{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8f2734",
   "metadata": {},
   "source": [
    "====================1 - Использование генерации запросов и ответов через API и ключ OpenAI===================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d9572",
   "metadata": {},
   "source": [
    "Для загрузки библиотек и модулей\n",
    "pip install openai langchain huggingface_hub langchain-openai langchain-community transformers langchain-huggingface -U -q"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2222ed56",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e424ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from getpass import getpass  # Для скрытого ввода API ключей\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = getpass(prompt=f\"Введите OpenAI-API ключ: \") #Ввод ключа\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key) #Создание клиента и подключение\n",
    "\n",
    "#print(client.models.list()) #Просмотр доступных моделей\n",
    "\n",
    "messages = [\n",
    "            {\"role\" : \"user\"\n",
    "             , \"content\" : \"Кто первый человек в космосе\"}\n",
    "             ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    max_tokens=100\n",
    "    ,model=\"gpt-3.5-turbo\"  #Выбранная модель\n",
    "    ,messages=messages      #Запрос\n",
    "    ,temperature=0.3        #Степень креативности ответа\n",
    "    )\n",
    "\n",
    "\n",
    "print(chat_completion.choices[0].message.content) #Принт ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Параметры на вход\n",
    "\n",
    "# max_tokens - максимальное количество токенов, генерируемых в сообщении\n",
    "\n",
    "# n - сколько вариантов ответа должно быть сгенерировано для каждого входного сообщения (по умолчанию 1)\n",
    "\n",
    "# temperature - влияет на степень случайности генерации (принимает значения от 0 до 2, по умолчанию 1). Высокое значение \n",
    "# температуры делает вероятности всех слов в выводе более равномерными, что приводит к более случайному\n",
    "#  и разнообразному тексту. При низком значении температуры модель будет склонна генерировать\n",
    "#  более предсказуемый и детерминированный текст.\n",
    "\n",
    "# top_p - тоже влияет на степень случайности генерации. \n",
    "# Определяет, какой процент наиболее вероятных слов будет включен в генерацию. \n",
    "# Например, если top-p равно 0.8, то модель будет использовать вероятности слов так, \n",
    "# чтобы включить в генерацию слова, составляющие 80% верхней части распределения вероятностей.\n",
    "\n",
    "# Рекомендуем изменять либо параметр temperature, либо top_p, но не оба одновременно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e39db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Структура ответа\n",
    "\n",
    "{\n",
    "  \"id\": \"chatcmpl-8B6YmCk5OiK7Z6RkRrkx72mEQaPGF\", #Айди ответа\n",
    "  \"object\": \"chat.completion\",      #Тип возвращаемого объекта\n",
    "  \"created\": 1697657516,            #Когда создан\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",    #Название модели\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,               #Индекс ответа\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",    #Роль\n",
    "        \"content\": \"1+1 equals 2.\"  #Ответ\n",
    "      },\n",
    "      \"finish_reason\": \"stop\"       #Причина остановки запроса (stop - нашел ответ, lenght - макс длина, filter - запрещенка)\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 10,    #Кол-во токенов для генерации запроса\n",
    "    \"completion_tokens\": 7, #Кол-во токенов для генерации ответа\n",
    "    \"total_tokens\": 17      #Суммарно сколько токенов ты потратил\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d3f4e9",
   "metadata": {},
   "source": [
    "====================2 - Использование генерации запросов и ответов через API и ключ OpenAI, но для участников курса===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b76452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первым человеком в космосе стал Юрий Гагарин. Он совершил свой исторический полет 12 апреля 1961 года на космическом корабле \"Восток-1\". Полет длился 108 минут, и Гагарин стал символом советской космической программы и важной фигурой в истории освоения космоса.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from getpass import getpass  # Для скрытого ввода API ключей\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "course_api_key = getpass(prompt=f\"Введите OpenAI-API ключ от создателей курса: \") #Ввод ключа\n",
    "#Это сделано для тех, у кого нет OpenAI ключа, но оч хочется попробовать\n",
    "\n",
    "client = OpenAI(api_key=course_api_key\n",
    "                ,base_url=\"https://aleron-llm.neuraldeep.tech\") #Создание клиента и подключение\n",
    "\n",
    "messages = [\n",
    "            {\"role\" : \"user\"\n",
    "             , \"content\" : \"Кто первый человек в космосе\"}\n",
    "             ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    max_tokens=100\n",
    "    ,model=\"gpt-4o-mini\"  #Выбранная модель\n",
    "    ,messages=messages      #Запрос\n",
    "    ,temperature=0.1        #Степень креативности ответа\n",
    "    )\n",
    "\n",
    "\n",
    "print(chat_completion.choices[0].message.content) #Принт ответа\n",
    "#Первым человеком в космосе стал Юрий Гагарин. \n",
    "# Он совершил свой исторический полет 12 апреля 1961 года на космическом корабле \"Восток-1\".\n",
    "#  Полет длился 108 минут, и Гагарин стал символом советской космической программы и важной\n",
    "#  фигурой в истории освоения космоса.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d39b0",
   "metadata": {},
   "source": [
    "===================3 - Использование генерации запросов и ответов через LangChain и API OpenAI, нужен также свой ключик===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a385719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "question = 'Кто был первым человеком на Луне'\n",
    "template = \"\"\"Вопрос {question} Ответ: дай короткий ответ\"\"\" #Шаблон запроса\n",
    "\n",
    "prompt = PromptTemplate(template=template\n",
    "                        ,input_variables=['question']) #Создаем промт\n",
    "\n",
    "open_ai_llm = ChatOpenAI() #Создаем модельку\n",
    "\n",
    "llm_chain = prompt | open_ai_llm #Создаем цепочку\n",
    "\n",
    "print(llm_chain.invoke(question).content)    #Принтуем ответ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "===================4 - Использование генерации запросов и ответов через LangChain и API OpenAI, через ключ от курса===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первым человеком на Луне был Нил Армстронг.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "question = 'Кто был первым человеком на Луне'\n",
    "template = \"\"\"Вопрос {question} Ответ: дай короткий ответ\"\"\" #Шаблон запроса\n",
    "\n",
    "prompt = PromptTemplate(template=template\n",
    "                        ,input_variables=['question']) #Создаем промт\n",
    "\n",
    "open_ai_llm = ChatOpenAI(api_key=course_api_key\n",
    "                         ,model=\"gpt-4o-mini\"\n",
    "                         ,base_url=\"https://aleron-llm.neuraldeep.tech\") #Создаем модельку\n",
    "\n",
    "llm_chain = prompt | open_ai_llm #Создаем цепочку\n",
    "\n",
    "print(llm_chain.invoke(question).content)    #Принтуем ответ\n",
    "#Первым человеком на Луне был Нил Армстронг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "===================5 - Использование генерации запросов и ответов через сервис HuggingFace, ключ из твоего ЛК===================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f9a23",
   "metadata": {},
   "source": [
    "Этот способ позволит тебе протестировать некоторые модельки прежде чем их скачивать\n",
    "https://huggingface.co/ - ссылка на сервис\n",
    "https://huggingface.co/models?pipeline_tag=text-generation&inference_provider=hf-inference&sort=trending - список моделек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#Инициализация модели\n",
    "hf_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"SmolLM3-3B\", # вводим название модели с HuggingFace\n",
    "    #repo_id=\"mistralai/Mistral-Nemo-Base-2407\",\n",
    "    #provider=\"novita\",\n",
    "    #task='conversational',\n",
    "    max_new_tokens=50,\n",
    "    huggingfacehub_api_token=\"\",\n",
    ")\n",
    "\n",
    "# build prompt template for simple question-answering\n",
    "template = \"\"\"Question: {question}.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = prompt | hf_llm\n",
    "\n",
    "question = \"When did man first fly into space?\"\n",
    "\n",
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2da13",
   "metadata": {},
   "source": [
    "===================6 - Запуск локально===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598a84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"D:\\\\Khabarov\\Репозиторий\\\\huggingface_cache\"  # Указываем диск D\n",
    "\n",
    "#Код позволяет сменить место для сохранения HuggingFace моделей (А мб и нет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "154d6b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db8cc2e07a84132a8155da52ce62d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\Khabarov\\Репозиторий\\huggingface_cache\\hub\\models--Qwen--Qwen3-4B-Base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce3decd8bc64bed908008819795b826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53cfc53d425468085bd9c1431c9755e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c94706215a45ca9e73cb7e03d9b20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022566a3d2c44b418b30fce51cb1c205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa9c27f31fd43bb86a11f330a91296d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/99.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f003b761eb24e07b13162fe917dc1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd571c9def004b1da875ec2ee608bbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d2e7ed3dbe48d2bfcd665e43c5047d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e87ffcbb901415e8a7a49de752a74de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a1551d8401486db2f570c91624ab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b526ef8c4d2e434b85c709e22df57f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "#Перед запуском установи pip3 install torch и pip3 install accelerate\n",
    "#Этот код используй для загрузки модели на локальный диск\n",
    "\n",
    "\n",
    "# Сначала загрузите модель и токенизатор отдельно\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    # \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\",\n",
    "    \"Qwen/Qwen3-4B-Base\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,  # Обязательно для кастомных моделей!\n",
    "    #quantization_config = None\n",
    ")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B-Base\")\n",
    "\n",
    "# Создайте pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=64,  # max_length устарел, используйте max_new_tokens\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Теперь создайте объект LLM\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a8d6df3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      6\u001b[39m prompt = PromptTemplate(template=template, input_variables=[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      8\u001b[39m llm_chain = prompt | llm\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3046\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3044\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3045\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3046\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3047\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3048\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:389\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    380\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m     **kwargs: Any,\n\u001b[32m    386\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    387\u001b[39m     config = ensure_config(config)\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    400\u001b[39m         .text\n\u001b[32m    401\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    759\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    763\u001b[39m     **kwargs: Any,\n\u001b[32m    764\u001b[39m ) -> LLMResult:\n\u001b[32m    765\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:971\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    957\u001b[39m     run_managers = [\n\u001b[32m    958\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    959\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    969\u001b[39m         )\n\u001b[32m    970\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    979\u001b[39m     run_managers = [\n\u001b[32m    980\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    981\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    989\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    782\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    783\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m     **kwargs: Any,\n\u001b[32m    789\u001b[39m ) -> LLMResult:\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    791\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    796\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    800\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    801\u001b[39m         )\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    803\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\langchain_huggingface\\llms\\huggingface_pipeline.py:315\u001b[39m, in \u001b[36mHuggingFacePipeline._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m batch_prompts = prompts[i : i + \u001b[38;5;28mself\u001b[39m.batch_size]\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m responses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:316\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    315\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1445\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1442\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1443\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1444\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m    124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1371\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1370\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:414\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    412\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    417\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2625\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2617\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2618\u001b[39m         input_ids=input_ids,\n\u001b[32m   2619\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2620\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2621\u001b[39m         **model_kwargs,\n\u001b[32m   2622\u001b[39m     )\n\u001b[32m   2624\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2625\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2636\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2637\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2638\u001b[39m         input_ids=input_ids,\n\u001b[32m   2639\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2640\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2641\u001b[39m         **model_kwargs,\n\u001b[32m   2642\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3609\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3607\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3608\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3609\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3611\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3612\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3613\u001b[39m     outputs,\n\u001b[32m   3614\u001b[39m     model_kwargs,\n\u001b[32m   3615\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3616\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:570\u001b[39m, in \u001b[36mQwen3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    565\u001b[39m output_hidden_states = (\n\u001b[32m    566\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    567\u001b[39m )\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:458\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    456\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:83\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         logger.warning(message)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:262\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:230\u001b[39m, in \u001b[36mQwen3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m attn_output, attn_weights = attention_interface(\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    219\u001b[39m     query_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    226\u001b[39m     **kwargs,\n\u001b[32m    227\u001b[39m )\n\u001b[32m    229\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\accelerate\\hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Khabarov\\Репозиторий\\llm_practice_course\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "question = \"Сколько будет 1 + 1\"\n",
    "template = \"\"\"Question: {question}.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "\n",
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2557a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who killed Kennedy?.\n",
      "\n",
      "Answer: A. The government.\n",
      "B. The media.\n",
      "C. The CIA.\n",
      "D. The political leadership.\n",
      "E. The left.\n",
      "Hint: The government is the main culprit for the murder of President Kennedy and the CIA, the media, and the left are the main culpr\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#А перед этим еще обнови pip3 install ipywidgets\n",
    "bloom = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"bigscience/bloom-1b7\",\n",
    "    task='text-generation',\n",
    "    model_kwargs={\n",
    "                    'temperature':0,\n",
    "                    'max_length':64,\n",
    "                },\n",
    "    device=-0.5,\n",
    ")\n",
    "\n",
    "question = \"Who killed Kennedy?\"\n",
    "template = \"\"\"Question: {question}.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = prompt | bloom\n",
    "\n",
    "\n",
    "print(llm_chain.invoke(question))\n",
    "#Все работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4411006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Кто был первым человеком на луне?.\n",
      "\n",
      "Answer: Я.\n",
      "\n",
      "A:\n",
      "\n",
      "Используйте два варианта написания, одна из которых:\n",
      "\n",
      "Мой прятельный платформа отправляет\n"
     ]
    }
   ],
   "source": [
    "question = \"Кто был первым человеком на луне?\"\n",
    "template = \"\"\"Question: {question}.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = prompt | bloom\n",
    "\n",
    "\n",
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who killed Kennedy?.\n",
      "\n",
      "Answer: Kennedy was shot by the assassin.\n",
      "\n",
      "Explanation: Kennedy was killed because he refused to help the traitors.\n",
      "\n",
      "Answer: They shot him because he refused to help them.\n",
      "\n",
      "Explanation: They shot him because he refused to help them.\n",
      "\n",
      "Answer: They shot him because he refused to\n"
     ]
    }
   ],
   "source": [
    "#Этот код запускает уже локальную модель (по идее), но такое ощущение, что предыдущий код тоже берет существующую модель, если она есть\n",
    "\n",
    "\n",
    "\n",
    "#А перед этим еще обнови pip3 install ipywidgets\n",
    "bloom = HuggingFacePipeline.from_model_id(\n",
    "    model_id=r\"C:\\Users\\n.khabarov\\.cache\\huggingface\\hub\\models--bigscience--bloom-1b7\\snapshots\\cc72a88036c2fb937d65efeacc57a0c2ef5d6fe5\",\n",
    "    task='text-generation',\n",
    "    model_kwargs={\n",
    "                    'temperature':0,\n",
    "                    'max_length':64,\n",
    "                },\n",
    "    device=-0.5,\n",
    ")\n",
    "\n",
    "question = \"Who killed Kennedy?\"\n",
    "template = \"\"\"Question: {question}.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = prompt | bloom\n",
    "\n",
    "\n",
    "print(llm_chain.invoke(question))\n",
    "#Все работает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c1660",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
